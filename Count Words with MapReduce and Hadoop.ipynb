{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count with mrjob\n",
    "\n",
    "`mrjob` is a Python package that helps you write and run Hadoop Streaming jobs. It supports Amazon's Elastic MapReduce (EMR) and it also works with your own Hadoop cluster.  It has been released as an open-source framework by Yelp and we will use it to interface with Hadoop due to its legibility and ease of use with MapReduce tasks.  \n",
    "\n",
    "Read through some of the [mrjob docs](http://mrjob.readthedocs.org/en/latest/index.html) or this [mrjob tutorial](https://pythonhosted.org/mrjob/guides/quickstart.html) \n",
    "\n",
    "Some important features of ```mrjob```:\n",
    "\n",
    "* It can run jobs on EMR, your own Hadoop cluster, or locally (for testing).\n",
    "* It can be used to write multi-step jobs, where one map-reduce step feeds into the next. \n",
    "\n",
    "## Exercise 1: Simple Count\n",
    "\n",
    "Do a simple word count on the [Reuters 20 Newsgroups dataset](http://qwone.com/~jason/20Newsgroups/) click [here](http://qwone.com/~jason/20Newsgroups/20news-19997.tar.gz) to download.  If that is unavailable look [here](http://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html).\n",
    "\n",
    "\n",
    "__STEP 1:__ Create a file `wordcounts.py` with the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from mrjob.job import MRJob\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "class MRWordFreqCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            yield (word.strip(punctuation).lower(), 1)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()\n",
    "\n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__STEP 2:__ Create a mini version of the dataset with these terminal commands: \n",
    "\n",
    "```bash\n",
    "    mkdir mini_20_newsgroups\n",
    "    mkdir mini_20_newsgroups/comp.windows.x\n",
    "    mkdir mini_20_newsgroups/rec.motorcycles\n",
    "    mkdir mini_20_newsgroups/sci.med\n",
    "    cp 20_newsgroups/comp.windows.x/663* mini_20_newsgroups/comp.windows.x\n",
    "    cp 20_newsgroups/rec.motorcycles/10311* mini_20_newsgroups/rec.motorcycles\n",
    "    cp 20_newsgroups/sci.med/5889* mini_20_newsgroups/sci.med\n",
    "    ```\n",
    "__STEP 3:__ From the terminal, execute the file with the mini folder `mini_20_newsgroups` and notice how it goes through each folder in the directory and performs the word count.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python wordcounts.py ../data/mini_20_newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output look pretty messy. But it does what we expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Word Counts by Topic\n",
    "\n",
    "Create a file `wordcounts_bytopic.py` with the following code:\n",
    "\n",
    "```Python\n",
    "from mrjob.job import MRJob\n",
    "from string import punctuation\n",
    "import os\n",
    "\n",
    "\n",
    "class MRWordFreqCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        file_path = os.environ['map_input_file']\n",
    "        topic = file_path.split('.')[-1].split('/')[0]\n",
    "        for word in line.split():\n",
    "            word = word.strip(punctuation).lower()\n",
    "            yield (topic + '_'+ word, 1)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python wordcounts_bytopic.py ../data/mini_20_newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: json and tokenization\n",
    "\n",
    "I have a json file containing NYT articles `articles.json`. We want to clean up the thext before counting the words. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize and Stem\n",
    "\n",
    "Lets Count the words in each section after we tokenize and stem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "the\n",
      "man\n",
      "on\n",
      "the\n",
      "phone\n",
      "said\n",
      "are\n",
      "you\n",
      "still\n",
      "come\n",
      "tonight\n",
      "it\n",
      "took\n",
      "a\n",
      "moment\n",
      "for\n",
      "me\n",
      "to\n",
      "realiz\n",
      "that\n",
      "he\n",
      "was\n",
      "call\n",
      "from\n",
      "distil\n",
      "to\n",
      "confirm\n",
      "my\n",
      "dinner\n",
      "reserv\n",
      "yes\n",
      "i\n",
      "repli\n",
      "cool\n",
      "he\n",
      "said\n",
      "and\n",
      "sound\n",
      "as\n",
      "if\n",
      "he\n",
      "meant\n",
      "it\n",
      "distil\n",
      "open\n",
      "in\n",
      "june\n",
      "on\n",
      "the\n",
      "corner\n",
      "of\n",
      "franklin\n",
      "street\n",
      "and\n",
      "west\n",
      "broadway\n",
      "in\n",
      "tribeca\n",
      "the\n",
      "former\n",
      "home\n",
      "of\n",
      "drew\n",
      "niepor\n",
      "layla\n",
      "and\n",
      "centrico\n",
      "the\n",
      "belli\n",
      "dancer\n",
      "and\n",
      "the\n",
      "frozenmargarita\n",
      "machin\n",
      "are\n",
      "gone\n",
      "but\n",
      "a\n",
      "certain\n",
      "effervesc\n",
      "remain\n",
      "so\n",
      "doe\n",
      "mr\n",
      "niepor\n",
      "hover\n",
      "in\n",
      "the\n",
      "background\n",
      "as\n",
      "guru\n",
      "to\n",
      "distil\n",
      "owner\n",
      "the\n",
      "firsttim\n",
      "restaurateur\n",
      "nick\n",
      "iovacchini\n",
      "and\n",
      "shane\n",
      "lyon\n",
      "the\n",
      "25yearold\n",
      "chef\n",
      "the\n",
      "space\n",
      "is\n",
      "bland\n",
      "handsom\n",
      "with\n",
      "dark\n",
      "wood\n",
      "and\n",
      "charcoal\n",
      "banquett\n",
      "breathless\n",
      "high\n",
      "ceil\n",
      "and\n",
      "quasimediev\n",
      "wheel\n",
      "chandeli\n",
      "like\n",
      "crown\n",
      "of\n",
      "fire\n",
      "one\n",
      "side\n",
      "is\n",
      "devot\n",
      "to\n",
      "the\n",
      "bar\n",
      "where\n",
      "the\n",
      "drink\n",
      "by\n",
      "benjamin\n",
      "wood\n",
      "are\n",
      "ladykil\n",
      "eleg\n",
      "with\n",
      "a\n",
      "knife\n",
      "twist\n",
      "occasion\n",
      "1980s\n",
      "mope\n",
      "rock\n",
      "shimmer\n",
      "from\n",
      "the\n",
      "speaker\n",
      "servic\n",
      "is\n",
      "confound\n",
      "friend\n",
      "almost\n",
      "coddl\n",
      "when\n",
      "i\n",
      "stood\n",
      "outsid\n",
      "read\n",
      "the\n",
      "post\n",
      "menu\n",
      "someon\n",
      "came\n",
      "hurri\n",
      "down\n",
      "the\n",
      "step\n",
      "to\n",
      "hand\n",
      "me\n",
      "my\n",
      "own\n",
      "copi\n",
      "so\n",
      "i\n",
      "wouldnt\n",
      "crane\n",
      "my\n",
      "neck\n",
      "he\n",
      "said\n",
      "on\n",
      "arriv\n",
      "and\n",
      "departur\n",
      "a\n",
      "host\n",
      "leapt\n",
      "to\n",
      "open\n",
      "the\n",
      "door\n",
      "the\n",
      "mission\n",
      "statement\n",
      "that\n",
      "preced\n",
      "one\n",
      "meal\n",
      "we\n",
      "are\n",
      "a\n",
      "modern\n",
      "american\n",
      "public\n",
      "hous\n",
      "the\n",
      "waiter\n",
      "inton\n",
      "was\n",
      "both\n",
      "unnecessari\n",
      "and\n",
      "slight\n",
      "coy\n",
      "about\n",
      "mr\n",
      "lyonss\n",
      "ambit\n",
      "yes\n",
      "wing\n",
      "are\n",
      "on\n",
      "the\n",
      "menu\n",
      "but\n",
      "they\n",
      "are\n",
      "jack\n",
      "up\n",
      "with\n",
      "gochujang\n",
      "korean\n",
      "ferment\n",
      "soybean\n",
      "and\n",
      "chile\n",
      "past\n",
      "borrow\n",
      "perhap\n",
      "from\n",
      "the\n",
      "larder\n",
      "at\n",
      "momofuku\n",
      "noodl\n",
      "bar\n",
      "where\n",
      "mr\n",
      "lyon\n",
      "work\n",
      "for\n",
      "a\n",
      "year\n",
      "there\n",
      "are\n",
      "occasion\n",
      "technic\n",
      "flourish\n",
      "like\n",
      "watermelon\n",
      "cube\n",
      "cryovac\n",
      "to\n",
      "intensifi\n",
      "their\n",
      "flavor\n",
      "and\n",
      "mushroom\n",
      "surround\n",
      "by\n",
      "puff\n",
      "of\n",
      "butteri\n",
      "onion\n",
      "soubis\n",
      "aerat\n",
      "by\n",
      "an\n",
      "isi\n",
      "siphon\n",
      "a\n",
      "tousl\n",
      "of\n",
      "dehydr\n",
      "and\n",
      "shave\n",
      "bacon\n",
      "adorn\n",
      "an\n",
      "openfac\n",
      "sandwich\n",
      "of\n",
      "heirloom\n",
      "tomato\n",
      "and\n",
      "basil\n",
      "on\n",
      "sourdough\n",
      "a\n",
      "blt\n",
      "of\n",
      "cours\n",
      "sunflow\n",
      "sprout\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "miss\n",
      "crunch\n",
      "other\n",
      "classic\n",
      "are\n",
      "updat\n",
      "rather\n",
      "than\n",
      "upend\n",
      "popcorn\n",
      "dust\n",
      "with\n",
      "garlic\n",
      "cumin\n",
      "and\n",
      "brewer\n",
      "yeast\n",
      "which\n",
      "evok\n",
      "chees\n",
      "snappi\n",
      "pickl\n",
      "ferment\n",
      "with\n",
      "gochugaru\n",
      "korean\n",
      "red\n",
      "chile\n",
      "powder\n",
      "pork\n",
      "rib\n",
      "glaze\n",
      "with\n",
      "more\n",
      "gochujang\n",
      "teas\n",
      "the\n",
      "sweetsalti\n",
      "border\n",
      "without\n",
      "stray\n",
      "too\n",
      "far\n",
      "in\n",
      "either\n",
      "direct\n",
      "onion\n",
      "ring\n",
      "batter\n",
      "with\n",
      "yuengl\n",
      "beer\n",
      "and\n",
      "tapioca\n",
      "flour\n",
      "are\n",
      "fri\n",
      "then\n",
      "frozen\n",
      "a\n",
      "theatric\n",
      "waiter\n",
      "boast\n",
      "that\n",
      "they\n",
      "had\n",
      "been\n",
      "brought\n",
      "to\n",
      "negat\n",
      "60\n",
      "degre\n",
      "and\n",
      "fri\n",
      "again\n",
      "they\n",
      "arriv\n",
      "nice\n",
      "sturdi\n",
      "the\n",
      "sole\n",
      "purpos\n",
      "of\n",
      "their\n",
      "exist\n",
      "to\n",
      "ferri\n",
      "the\n",
      "narcoticlik\n",
      "condiment\n",
      "burn\n",
      "scallion\n",
      "cut\n",
      "with\n",
      "jalapeo\n",
      "and\n",
      "mayonnais\n",
      "with\n",
      "the\n",
      "sting\n",
      "of\n",
      "preserv\n",
      "lime\n",
      "the\n",
      "substanti\n",
      "burger\n",
      "which\n",
      "the\n",
      "menu\n",
      "modest\n",
      "refrain\n",
      "from\n",
      "tell\n",
      "you\n",
      "is\n",
      "made\n",
      "with\n",
      "grassf\n",
      "organicgrainfinish\n",
      "beef\n",
      "is\n",
      "abet\n",
      "by\n",
      "what\n",
      "may\n",
      "be\n",
      "the\n",
      "finest\n",
      "version\n",
      "of\n",
      "tater\n",
      "tot\n",
      "in\n",
      "town\n",
      "the\n",
      "grate\n",
      "potato\n",
      "cook\n",
      "until\n",
      "just\n",
      "underdon\n",
      "and\n",
      "then\n",
      "crisp\n",
      "with\n",
      "wondra\n",
      "flour\n",
      "everyth\n",
      "here\n",
      "goe\n",
      "to\n",
      "11\n",
      "one\n",
      "diner\n",
      "marvel\n",
      "duck\n",
      "bread\n",
      "and\n",
      "fri\n",
      "like\n",
      "chicken\n",
      "is\n",
      "brazen\n",
      "and\n",
      "irresist\n",
      "despit\n",
      "the\n",
      "oversweet\n",
      "accompani\n",
      "waffl\n",
      "a\n",
      "spongi\n",
      "slab\n",
      "of\n",
      "brioch\n",
      "dredg\n",
      "in\n",
      "custard\n",
      "like\n",
      "french\n",
      "toast\n",
      "even\n",
      "broccoli\n",
      "turn\n",
      "wanton\n",
      "flung\n",
      "with\n",
      "sliver\n",
      "of\n",
      "duck\n",
      "bacon\n",
      "and\n",
      "pickl\n",
      "watermelon\n",
      "rind\n",
      "in\n",
      "a\n",
      "fish\n",
      "sauc\n",
      "vinaigrett\n",
      "with\n",
      "wait\n",
      "for\n",
      "it\n",
      "a\n",
      "dollop\n",
      "of\n",
      "duck\n",
      "fat\n",
      "but\n",
      "liver\n",
      "pt\n",
      "serv\n",
      "with\n",
      "plume\n",
      "of\n",
      "bake\n",
      "dehydr\n",
      "chicken\n",
      "skin\n",
      "now\n",
      "this\n",
      "is\n",
      "confront\n",
      "my\n",
      "mission\n",
      "in\n",
      "life\n",
      "is\n",
      "to\n",
      "make\n",
      "skinni\n",
      "girl\n",
      "fat\n",
      "mr\n",
      "lyon\n",
      "told\n",
      "my\n",
      "tabl\n",
      "he\n",
      "got\n",
      "a\n",
      "laugh\n",
      "but\n",
      "the\n",
      "crackl\n",
      "were\n",
      "abandon\n",
      "after\n",
      "one\n",
      "bite\n",
      "the\n",
      "onli\n",
      "logic\n",
      "end\n",
      "to\n",
      "such\n",
      "a\n",
      "meal\n",
      "is\n",
      "smore\n",
      "deconstruct\n",
      "as\n",
      "is\n",
      "the\n",
      "fashion\n",
      "with\n",
      "a\n",
      "hickorysmok\n",
      "grahamflour\n",
      "cake\n",
      "a\n",
      "torch\n",
      "smear\n",
      "of\n",
      "marshmallow\n",
      "fluff\n",
      "dark\n",
      "chocol\n",
      "pud\n",
      "and\n",
      "graham\n",
      "cracker\n",
      "broken\n",
      "on\n",
      "top\n",
      "it\n",
      "is\n",
      "obvious\n",
      "and\n",
      "no\n",
      "less\n",
      "pleasur\n",
      "for\n",
      "it\n",
      "kari\n",
      "rak\n",
      "previous\n",
      "at\n",
      "bouchon\n",
      "bakeri\n",
      "will\n",
      "introduc\n",
      "a\n",
      "new\n",
      "dessert\n",
      "menu\n",
      "this\n",
      "month\n",
      "or\n",
      "take\n",
      "a\n",
      "shot\n",
      "of\n",
      "moonshin\n",
      "with\n",
      "an\n",
      "apricot\n",
      "shrub\n",
      "as\n",
      "a\n",
      "chaser\n",
      "it\n",
      "edg\n",
      "everyth\n",
      "in\n",
      "halo\n",
      "and\n",
      "can\n",
      "make\n",
      "you\n",
      "believ\n",
      "that\n",
      "a\n",
      "modern\n",
      "american\n",
      "public\n",
      "hous\n",
      "whatev\n",
      "that\n",
      "is\n",
      "is\n",
      "where\n",
      "you\n",
      "want\n",
      "to\n",
      "be\n",
      "distil\n",
      "211\n",
      "west\n",
      "broadway\n",
      "franklin\n",
      "street\n",
      "212\n",
      "6019514\n",
      "distillednycom\n",
      "recommend\n",
      "blt\n",
      "chill\n",
      "char\n",
      "broccoli\n",
      "porgi\n",
      "burger\n",
      "wing\n",
      "countri\n",
      "fri\n",
      "duck\n",
      "and\n",
      "waffl\n",
      "pork\n",
      "rib\n",
      "smore\n",
      "price\n",
      "5\n",
      "to\n",
      "29\n",
      "open\n",
      "night\n",
      "for\n",
      "dinner\n",
      "saturday\n",
      "and\n",
      "sunday\n",
      "for\n",
      "brunch\n",
      "reserv\n",
      "accept\n",
      "wheelchair\n",
      "access\n",
      "entranc\n",
      "is\n",
      "up\n",
      "a\n",
      "short\n",
      "flight\n",
      "of\n",
      "stair\n",
      "from\n",
      "the\n",
      "sidewalk\n",
      "restroom\n",
      "have\n",
      "handrail\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import os\n",
    "import json\n",
    "\n",
    "sno = SnowballStemmer('english')\n",
    "\n",
    "def my_test_tokenizer(text):\n",
    "    for s in text:\n",
    "            s = s.strip().encode(\"ascii\", \"ignore\").decode('utf-8').lower()\n",
    "            translator = s.maketrans('', '', punctuation)\n",
    "            no_punct = s.translate(translator)\n",
    "            for word in word_tokenize(no_punct):\n",
    "                w = sno.stem(word)\n",
    "                print(w)\n",
    "                \n",
    "with open('data/articles.json') as f:\n",
    "        for line in f:\n",
    "            d = json.loads(line)\n",
    "            headline = d['headline']['main']\n",
    "            section = d['section_name']\n",
    "            my_test_tokenizer(d['content'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python wordcounts_json.py ../data/articles.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Most Common Topic by Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to count each word by topic, but then figure out what topic is most common for each word. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python topic_from_count.py ../data/articles.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
